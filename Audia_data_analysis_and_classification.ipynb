{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoMFQ-IwwoFc"
      },
      "source": [
        "## **Audio data analysis and classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9m8fe1K2PVP"
      },
      "source": [
        "Sound is represented in the form of an audio signal having parameters such as *frequency, bandwidth, decibel*, etc.\n",
        "\n",
        "A typical audio signal can be expressed as a function of amplitude and time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVOirJzjwevR",
        "outputId": "12b50f6b-941d-41e9-a734-a68277cacaec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-5.27.1-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.55.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
            "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.27.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.27.1\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install --upgrade resampy\n",
        "!pip install --upgrade protobuf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fupWjtyUxJ1l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6cZO5Z4xrpz"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9rKEm-7xZF5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgiYIh4Hxdoh"
      },
      "outputs": [],
      "source": [
        "# Audio file upload\n",
        "audio_dataset_path = '/content/drive/MyDrive/Audio_data'T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74z8Y4q-qvoJ"
      },
      "source": [
        "# **Terms to know audio in digital form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnBPJh-CrDp8"
      },
      "source": [
        "# Frequency (Hz)\n",
        "*   Frequency describes the differences of wave lengths\n",
        "*   We interprate the frequency as high and low pitches\n",
        "\n",
        "# Intensity (db/Power)\n",
        "*   Intensity describes the amplitude (i.e., height) of the wave\n",
        "*   Change in intensity but not frequency (called loudness)\n",
        "*   Change in frequency but not intensity (called pitch)\n",
        "\n",
        "# Sample Rate\n",
        "\n",
        "* The sample rate is the **number of samples carried out** by the selected audio per second, measured either in Hz or kHz\n",
        "*   Sample rate is specific to how the computer reads in the audio file (i.e., a discrete representation of a audio file)\n",
        "*   Any music file recorded with a sample rate and bit depth higher than 44.1kHz/16-bit is considered high definition (HD) audio.\n",
        "* In a typical digital audio CD recording, the sampling rate is 44,100 or 44.1kHz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF68Z7WtrDTR"
      },
      "outputs": [],
      "source": [
        "audio_files = glob('/content/drive/MyDrive/Audio_data/*/*.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAcl7-fIAi3U"
      },
      "outputs": [],
      "source": [
        "print(audio_files[10])\n",
        "len(audio_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XgcduyH-UjJ"
      },
      "source": [
        "##Audio data processing using librosa library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oonto_hiq5He"
      },
      "outputs": [],
      "source": [
        "file_name = audio_files[56]\n",
        "print(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nis2FoVyL8T"
      },
      "outputs": [],
      "source": [
        "#Play an audio file\n",
        "ipd.Audio(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKNQOsyzzHAZ"
      },
      "outputs": [],
      "source": [
        "#Extracting audio file information using librosa\n",
        "#Load an audio file as a floating point time series.\n",
        "\n",
        "data, sample_rate_default = librosa.load(file_name) #load() returns time-series data (i.e., frequency) of audio signal and sampling rate\n",
        "#load(path_to_file, *[, sr, mono, offset, duration, ...]) the other parameters like sr, mono, offset, duration, ... are optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UrJIQtJ3EuF"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8FXBB4D-EqQ"
      },
      "outputs": [],
      "source": [
        "#This is the default sample rate\n",
        "sample_rate_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv-kHtNO-LSf"
      },
      "outputs": [],
      "source": [
        "data[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8kbklJrB2sL"
      },
      "outputs": [],
      "source": [
        "#Printing the basic information of the audio file\n",
        "print(f\"Type of audio data:{type(data)}\")\n",
        "#print(f\"Shape of audio data:{data.shape}\")\n",
        "print(f\"Type of sample rate:{type(sample_rate_default)}\")\n",
        "print(f\"Sample rate(by default): {sample_rate_default}\") #Print the sample rate\n",
        "print(f\"Audio data shape: {data.shape}\") #print the size of audio data\n",
        "print(f\"First 10 values of the Audio data : {data[:10]}\") #print first 10 values of audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0kJqpDrO_Fh"
      },
      "outputs": [],
      "source": [
        "#Resampling the sample rate with 44.1kHz of a audio file\n",
        "audio_data, sample_rate = librosa.load(file_name, sr=44100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-E7Rzv1YPcgR"
      },
      "outputs": [],
      "source": [
        "sample_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBVfw17uP9pK"
      },
      "outputs": [],
      "source": [
        "#Printing the basic information of the audio file with different sample rate\n",
        "print(f\"Type of audio data:{type(audio_data)}\")\n",
        "print(f\"Type of sample rate:{type(sample_rate)}\")\n",
        "print(f\"Sample rate: {sample_rate}\") #Print the sample rate\n",
        "print(f\"Audio data shape: {audio_data.shape}\") #Change in the sample rate changes the size of audio data\n",
        "print(f\"First 10 values of the Audio data : {audio_data[:10]}\") #also change the values of audio data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rFsqTaw2fiO"
      },
      "source": [
        "# Handling audio data with different Channels\n",
        "\n",
        "\n",
        "*   Mono Channel\n",
        "*   Stereo Channel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgv2KB6W2es2"
      },
      "outputs": [],
      "source": [
        "audio_data_stereo_default, sample_rate = librosa.load(file_name, mono=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDKTA0CH4_zW"
      },
      "outputs": [],
      "source": [
        "print(f\"Audio data shape: {audio_data_stereo_default.shape}\") #audio_data_stereo_default.shape == (N_channels,\n",
        "#the first channel as audio_data_stereo_default[0] and the second channel as audio_data_stereo_default[1],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA0v_ym43Bxn"
      },
      "outputs": [],
      "source": [
        "#Printing the basic information of the audio file with stereo channel\n",
        "print(f\"Type of audio data:{type(audio_data_stereo_default)}\")\n",
        "#print(f\"Shape of audio data:{audio_data_stereo.shape}\")\n",
        "print(f\"Type of sample rate:{type(sample_rate)}\")\n",
        "print(f\"Sample rate(by default): {sample_rate}\") #Print the sample rate\n",
        "print(f\"Audio data shape: {audio_data_stereo_default.shape}\") #Change in the sample rate changes the size of audio data\n",
        "print(f\"First 10 values of the Audio data : {audio_data_stereo_default[:10]}\") #also change the values of audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAbskAiJ5Z-9"
      },
      "outputs": [],
      "source": [
        "print(f\"First channel of the Audio data : {audio_data_stereo_default[0]}\")\n",
        "print(f\"Second channel of the Audio data : {audio_data_stereo_default[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYIUlI1g4bEu"
      },
      "outputs": [],
      "source": [
        "audio_data_stereo, sample_rate = librosa.load(file_name, sr=44100, mono=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bpcihad4q92"
      },
      "outputs": [],
      "source": [
        "#Printing the basic information of the audio file with stereo channel\n",
        "print(f\"Type of audio data:{type(audio_data_stereo)}\")\n",
        "#print(f\"Shape of audio data:{audio_data_stereo.shape}\")\n",
        "print(f\"Type of sample rate:{type(sample_rate)}\")\n",
        "print(f\"Sample rate: {sample_rate}\") #Print the sample rate\n",
        "print(f\"Audio data shape: {audio_data_stereo.shape}\") #Change in the sample rate changes the size of audio data\n",
        "print(f\"First 10 values of the Audio data : {audio_data_stereo[:10]}\") #also change the values of audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4lmrohI7F5u"
      },
      "outputs": [],
      "source": [
        "print(f\"First channel of the Audio data : {audio_data_stereo[0]}\")\n",
        "print(f\"Second channel of the Audio data : {audio_data_stereo[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmOzhDr681JE"
      },
      "source": [
        "*Converting audio from stereo to mono channel*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtSqunPh80Pt"
      },
      "outputs": [],
      "source": [
        "#to_mono() convert an audio signal to mono by averaging samples across channels.\n",
        "audio_data_mono = librosa.to_mono(audio_data_stereo)\n",
        "print(audio_data_mono.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRBg5gGfRk8a"
      },
      "source": [
        "# **Ploting audio data (Waveform Visulization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaYNLxJwCvQh"
      },
      "outputs": [],
      "source": [
        "# One way to Plot audio data\n",
        "librosa.display.waveshow(data, sr=sample_rate_default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kDl2LDDREwy"
      },
      "outputs": [],
      "source": [
        "# audio data with different sample rate\n",
        "librosa.display.waveshow(audio_data, sr=sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWVl8eedDwpZ"
      },
      "outputs": [],
      "source": [
        "#Alternate way to plot audio data\n",
        "pd.Series(data).plot(figsize=(8, 3),\n",
        "                     lw=1,\n",
        "                     title=\"Raw audio data example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HPC_FNzEvnt"
      },
      "outputs": [],
      "source": [
        "#Trim the audio data\n",
        "data_trimmed, _ = librosa.effects.trim(data)\n",
        "print(data_trimmed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_-dCcVrFRN5"
      },
      "outputs": [],
      "source": [
        "pd.Series(data_trimmed).plot(figsize=(8, 3),\n",
        "                     lw=1,\n",
        "                     title=\"Raw audio data (trimmed) example\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5gIQNfPGR9f"
      },
      "outputs": [],
      "source": [
        "#Apply slicing\n",
        "pd.Series(data[7000:9000]).plot(figsize=(8, 3),\n",
        "                     lw=1,\n",
        "                     title=\"Raw audio data example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNP2gs2rHFJ_"
      },
      "source": [
        "**Spectogram Visualization**\n",
        "\n",
        "\n",
        "*   A spectrogram is a visual way of representing the  **frequency of sound** or  **signal strength**, or **loudness**, of a signal over time at various frequencies present in a particular waveform.\n",
        "* Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.\n",
        "*   Spectrogram are sometimes called **sonographs, voiceprint, or voicegrams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RZiLNhIG6b7"
      },
      "outputs": [],
      "source": [
        "#Applying fourier transformation (Short-time fourier transform)\n",
        "#stft() converts data into short term Fourier transform.\n",
        "#STFT converts signals such that we can know the amplitude of the given frequency at a given time.\n",
        "data_transformed = librosa.stft(data)\n",
        "data_db = librosa.amplitude_to_db(np.abs(data_transformed), ref=np.max)\n",
        "data_db.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T4xDtFFIJTN"
      },
      "outputs": [],
      "source": [
        "#Ploting the transformed audio (Spectogram)\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "img = librosa.display.specshow(data = data_db, #specshow is used to display a spectrogram.\n",
        "                              # sr = 44100,\n",
        "                               x_axis='time',\n",
        "                               y_axis='log',\n",
        "                               ax=ax)\n",
        "ax.set_title('Spectogram Example')\n",
        "fig.colorbar(img, ax=ax, format=f'%0.2f')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i8azPDKJ7HV"
      },
      "source": [
        "**Mel Spectogram**\n",
        "\n",
        "The mel-spectrogram, based on the auditory-based mel-frequency scale, provides better resolution for lower frequencies than the spectrogram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ahWgs_QKA1P"
      },
      "outputs": [],
      "source": [
        "data_mel = librosa.feature.melspectrogram(y=data,\n",
        "                                          sr=sample_rate,\n",
        "                                          n_mels=20)\n",
        "data_mel_db = librosa.amplitude_to_db(data_mel, ref=np.max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8P3sYVLK_I_"
      },
      "outputs": [],
      "source": [
        "#Ploting the transformed audio (Spectogram)\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "img = librosa.display.specshow(data = data_mel_db,\n",
        "                               x_axis='time',\n",
        "                               y_axis='log',\n",
        "                               ax=ax)\n",
        "ax.set_title('Mel Spectogram Example')\n",
        "fig.colorbar(img, ax=ax, format=f'%0.2f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbdhX569Krut"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dft_input = data[:4096]\n",
        "\n",
        "# calculate the DFT\n",
        "window = np.hanning(len(dft_input))\n",
        "windowed_input = dft_input * window\n",
        "dft = np.fft.rfft(windowed_input)\n",
        "# get the frequency bins\n",
        "frequency = librosa.fft_frequencies(sr=sample_rate, n_fft=len(dft_input))\n",
        "# get the amplitude spectrum in decibels\n",
        "amplitude = np.abs(dft)\n",
        "amplitude_db = librosa.amplitude_to_db(amplitude, ref=np.max)\n",
        "\n",
        "plt.figure().set_figwidth(12)\n",
        "plt.plot(frequency, amplitude_db)\n",
        "plt.xlabel(\"Frequency (Hz)\")\n",
        "plt.ylabel(\"Amplitude (dB)\")\n",
        "plt.xscale(\"log\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BNlxqxiz1ao"
      },
      "outputs": [],
      "source": [
        "file_name = audio_files[39]\n",
        "plt.figure(figsize=(14, 9))\n",
        "ipd.Audio(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RQ0nA8K9gXL"
      },
      "outputs": [],
      "source": [
        "data, sample_rate = librosa.load(file_name)\n",
        "librosa.display.waveshow(data, sr=sample_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6Vcaluv-cro"
      },
      "source": [
        "#Reading audio data using scipy.io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceoe8tfA9lRO"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile as wav\n",
        "wave_sample_rate, wave_audio = wav.read(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P8b_ST0-v6O"
      },
      "outputs": [],
      "source": [
        "wave_sample_rate #Default sample rate in this case 48.0 KHz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIaWCant-4uH"
      },
      "outputs": [],
      "source": [
        "wave_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGl6Br7u-6hW"
      },
      "outputs": [],
      "source": [
        "#Printing the basic information of the audio file with different sample rate\n",
        "print(f\"Type of audio data:{type(wave_audio)}\")\n",
        "print(f\"Type of sample rate:{type(wave_sample_rate)}\")\n",
        "print(f\"Sample rate(by default): {wave_sample_rate}\") #Print the sample rate\n",
        "print(f\"Audio data shape: {wave_audio.shape}\") #Change in the sample rate changes the size of audio data\n",
        "print(f\"First 10 values of the Audio data : {wave_audio[:10]}\") #also change the values of audio data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N89yHoHdVbd3"
      },
      "source": [
        "# **Feature extraction from Audio data**\n",
        "Every audio signal consists of many features.\n",
        "\n",
        "However, we must extract the characteristics that are relevant to the problem we are trying to solve.\n",
        "\n",
        "A audio data consist of mainly following types of features:\n",
        "\n",
        "\n",
        "*   Spectral features (or frequency-based features)\n",
        "*   Time-domain features: Zero crossing rate, amplitude envelope, and RMS energy\n",
        "*   Time-frequency domain features\n",
        "\n",
        "*Spectral features (frequency-based features)*, are obtained by converting the time-based signal into the frequency domain using the Fourier Transform, like fundamental frequency, frequency components, spectral centroid, spectral flux, spectral density, spectral roll-off, etc.\n",
        "\n",
        "*Time domain:* These are extracted from waveforms of the raw audio. Zero crossing rate, amplitude envelope, and RMS energy are examples.\n",
        "\n",
        "*Time-frequency representation:* These features combine both the time and frequency components of the audio signal.\n",
        "\n",
        "The time-frequency representation is obtained by applying the Short-Time Fourier Transform (STFT) on the time domain waveform. Spectrogram, mel-spectrogram, and constant-Q transform are examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9MoAG9EUSb3"
      },
      "source": [
        "**Mel-Frequency Cepstral Coefficients(MFCCs)**\n",
        "\n",
        "* The Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10–20) that concisely describe the overall shape of a spectral envelope.\n",
        "* It models the characteristics of the human voice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAT_us-vTbQ6"
      },
      "outputs": [],
      "source": [
        "audio, sample_rate = librosa.load(file_name)\n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate)#Number of mfcc to be returned, default value is 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zezOctsr6DGI"
      },
      "outputs": [],
      "source": [
        "mfccs_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI70eaIaU-w5"
      },
      "outputs": [],
      "source": [
        "mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
        "mfccs_scaled_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7cA8cL0VRnj"
      },
      "outputs": [],
      "source": [
        "mfccs_scaled_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49maSNYvWs-n"
      },
      "source": [
        "**Environmental sound classification** (on UrbanSound8K dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50h5thQjWm7E"
      },
      "outputs": [],
      "source": [
        "#Loading the dataset\n",
        "sound_data = pd.read_csv('/content/drive/MyDrive/Audio_data/UrbanSound8K.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UryjmD-cXl-x"
      },
      "source": [
        "#Know your dataset\n",
        "*Data preprocessing and visualization*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWr3zZsGYEau"
      },
      "outputs": [],
      "source": [
        "sound_data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcYUT6uNXlQ5"
      },
      "outputs": [],
      "source": [
        "sound_data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJeXZ_BrX0b8"
      },
      "outputs": [],
      "source": [
        "sound_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZEM43ALYT0W"
      },
      "outputs": [],
      "source": [
        "sound_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfoVWXnnYaF_"
      },
      "outputs": [],
      "source": [
        "#checking for the null values\n",
        "sound_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flpMpAlzYnEz"
      },
      "outputs": [],
      "source": [
        "#checking for the na values\n",
        "sound_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wyWXymrYv_D"
      },
      "outputs": [],
      "source": [
        "sound_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81o01FlhY19X"
      },
      "outputs": [],
      "source": [
        "sound_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDgQ8MSMZn1z"
      },
      "outputs": [],
      "source": [
        "#Checking whether dataset is balenced or not\n",
        "sound_data['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H13p7fiZJZy"
      },
      "source": [
        " **Exploratory data analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAHdsQU3Y5CS"
      },
      "outputs": [],
      "source": [
        "# Distribution of classes\n",
        "class_distribution = sound_data['class'].value_counts()\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=class_distribution.index, y=class_distribution.values)\n",
        "plt.title(\"Class Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtV_H-24Zg8o"
      },
      "outputs": [],
      "source": [
        "# Duration of audio files\n",
        "sound_data['duration'] = sound_data['end'] - sound_data['start']\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(sound_data['duration'], bins=50, kde=True)\n",
        "plt.title(\"Distribution of Audio Duration\")\n",
        "plt.xlabel(\"Duration (seconds)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBN3m7jgZ1uJ"
      },
      "outputs": [],
      "source": [
        "# Define a function to plot audio waveforms\n",
        "def plot_waveform(file_path):\n",
        "    #Plot the audio in wave form\n",
        "    audio, sr = librosa.load(file_path)\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    librosa.display.waveshow(audio, sr=sr)\n",
        "    plt.title(\"Audio Waveform\")\n",
        "    plt.show()\n",
        "    #Plot the audio in spectrogram\n",
        "    data, sr = librosa.load(file_path)\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(data)), ref=np.max)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    librosa.display.specshow(D, y_axis='linear')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Linear-frequency spectrogram')\n",
        "    ipd.Audio(file_path)\n",
        "\n",
        "\n",
        "# Choose a few audio files to visualize (you can change the file paths)\n",
        "sample_audio_paths = ['/content/drive/MyDrive/Audio_data/fold5/100263-2-0-3.wav',\n",
        "                      '/content/drive/MyDrive/Audio_data/fold2/102871-8-0-10.wav',\n",
        "                      '/content/drive/MyDrive/Audio_data/fold3/103199-4-1-0.wav']\n",
        "\n",
        "#for audio_path in sample_audio_paths:\n",
        "#    plot_waveform(audio_path)\n",
        "\n",
        "sample_audio_paths = audio_files[:10]\n",
        "for audio_path in sample_audio_paths:\n",
        "    plot_waveform(audio_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-twHXBw1h7wD"
      },
      "source": [
        "#Extracting MFCC feature for each audio file\n",
        "Here we will be using Mel-Frequency Cepstral Coefficients(MFCC) from the audio samples.\n",
        "\n",
        "The MFCC summarises the frequency distribution across the window size, so it is possible to analyse both the frequency and time characteristics of the sound.\n",
        "\n",
        "These audio representations will allow us to identify features for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS6bR4JCaHf3"
      },
      "outputs": [],
      "source": [
        "#Defining a function to extract MFCC audio features of a audio file\n",
        "\n",
        "def feature_extractor(file_name):\n",
        "  audio, sample_rate = librosa.load(file_name, res_type = 'kaiser_fast')\n",
        "  mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "  mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "  return mfccs_scaled_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoVbcHlrehZE"
      },
      "outputs": [],
      "source": [
        "# Features extraction from all audio files (MFCC)\n",
        "extracted_features=[]\n",
        "\n",
        "for index_num, row in tqdm(sound_data.iterrows()):\n",
        "     file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "     print(file_name)\n",
        "     final_class_labels=row[\"class\"]\n",
        "     data=feature_extractor(file_name)\n",
        "     extracted_features.append([data,final_class_labels])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBed_Vn0emLP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "#pickle.dump(extracted_features,open('/content/drive/MyDrive/Audio_data/extracted.pkl','wb'))\n",
        "loaded_model = pickle.load(open('/content/drive/MyDrive/Audio_data/extracted.pkl','rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWrzW_-LmJ0b"
      },
      "outputs": [],
      "source": [
        "# Converting extracted_features to Pandas dataframe\n",
        "extracted_features_df=pd.DataFrame(loaded_model,columns=['feature','class'])\n",
        "extracted_features_df.head()\n",
        "# Data Frame Saving\n",
        "extracted_features_df.to_csv(\"UrbanSound8K_DF.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISpLbLnxm7b7"
      },
      "outputs": [],
      "source": [
        "# Data Splitting\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z48Ph3zlE09o"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otVaKS37E2a7"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cHy_RDYIiM7"
      },
      "outputs": [],
      "source": [
        "# Import Libraries for Label Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y_label = labelencoder.fit_transform(y)\n",
        "y=to_categorical(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11K03oSoE5Sn"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS1uaihLE8Em"
      },
      "outputs": [],
      "source": [
        "print(y.shape)\n",
        "print(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cDlrD_ME-EJ"
      },
      "outputs": [],
      "source": [
        "#Train-test spliting\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBC2EYYMFoUv"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "X_scale = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn_oPAWGGJ-G"
      },
      "outputs": [],
      "source": [
        "X_test_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XAXw0H8GpTL"
      },
      "outputs": [],
      "source": [
        "X_train_std.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDKpB7XnG7_d"
      },
      "outputs": [],
      "source": [
        "X_test_std.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU89GRT4HARg"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9TNT-wUHDbs"
      },
      "outputs": [],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTniiKsfHVhu"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWpzIyOxHFzf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, f1_score, recall_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBG_EFUEHjj_"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvo7lsHpHrD8"
      },
      "outputs": [],
      "source": [
        "num_labels = y.shape[1]\n",
        "print(num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EChsp0rI2Xb"
      },
      "outputs": [],
      "source": [
        "#Model Creation\n",
        "model = Sequential()\n",
        "#First layer\n",
        "model.add(Dense(1600, input_shape =(X.shape[1], )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#Second layer\n",
        "model.add(Dense(800))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#third layer\n",
        "model.add(Dense(400))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "#Output layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObiU821CJl1Y"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0f54uwBLGDO"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNgWCa9QLPkU"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "num_batch_size = 128\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.h5', verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "y_pred=model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctMcIjnQLXpQ"
      },
      "outputs": [],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8txOXshA_pf"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model,open('/content/model.pkl','wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZFWoRq3ByA_"
      },
      "source": [
        "# Test on New audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEF6aFUhBrKE"
      },
      "outputs": [],
      "source": [
        "#Extracting feature of new audio file\n",
        "#filename=\"/content/drive/MyDrive/Audio_test/104327-2-0-4.wav\"\n",
        "file_name = audio_files[354]\n",
        "#print(file_name)\n",
        "audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEQQrclgCAMs"
      },
      "outputs": [],
      "source": [
        "mfccs_scaled_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghXesc2kCD-E"
      },
      "outputs": [],
      "source": [
        "#Predicting the class for new data\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "print(mfccs_scaled_features.shape)\n",
        "predicted_label = np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
        "print('Predicted Label:',predicted_label)\n",
        "print('Predicted Class:',prediction_class[0])\n",
        "ipd.Audio(file_name)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
